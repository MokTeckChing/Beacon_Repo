{
 "cells": [
  {
   "cell_type": "raw",
   "id": "decimal-possible",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: icedot and mochi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-wallpaper",
   "metadata": {},
   "source": [
    "# Imports\n",
    "do not edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "overall-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-boutique",
   "metadata": {},
   "source": [
    "# Change Me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nutritional-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name1 = \"SMR\" # Temp 1 abbreviation\n",
    "name2 = \"YZC\" # Temp 2 abbreviation\n",
    "namecol = \"SID1\" # Name of the column for staff ID\n",
    "token = \"token\" # spelling of \"token\" column. Capitalization matters.\n",
    "\n",
    "# if reading excel files, change the \"csv\" to \"excel\" and change the filename. Take note it will only read the first sheet.\n",
    "data = pd.read_csv(\"data/comb2.csv\")\n",
    "\n",
    "# test cases for testing code\n",
    "#test1 = pd.read_csv(\"test/test1.csv\") # control\n",
    "#test2 = pd.read_csv(\"test/test2.csv\") # differences in values\n",
    "#test3 = pd.read_csv(\"test/test3.csv\") # differences in rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-skiing",
   "metadata": {},
   "source": [
    "# Function\n",
    "do not edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fleet-command",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following 44 tokens are missing from YZC's dataset: ['2090574M', '3037490M', '6075068M', '2080789M', '2023468M', '1042834M', '5068494M', '1078035M', '1070886M', '7079115M', '2078062M', '5044397M', '9060268M', '7074125M', '5011962M', '4064830M', '6066041M', '9089513M', '1056421M', '7075990M', '6089504M', '2105686M', '7039396M', '9003223M', '2012064M', '3099308M', '3033710M', '4091856M', '8048185M', '7030225M', '4043360M', '9081160M', '2049574M', '2068464M', '1048339M', '7044434M', '4001708M', '9029392M', '8000553M', '3044606M', '5076102M', '4055376M', '1039181M', '2019513M']\n",
      "\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1 = data[data[namecol]==name1]\n",
    "data2 = data[data[namecol]==name2]\n",
    "\n",
    "#function to extract missing rows and equalize datasets\n",
    "\n",
    "def de_dupe_clean(df1, df2, namecol, token):\n",
    "\n",
    "    # removing name columns (if datasets start off merged, and are differentiated by a column's value)\n",
    "    \n",
    "    df1 = df1.drop(columns = namecol)\n",
    "    df2 = df2.drop(columns = namecol)\n",
    "    \n",
    "    # merging datasets to extract missing rows\n",
    "    \n",
    "    df_merged = pd.merge(df1, \n",
    "                         df2,\n",
    "                         how = 'outer',\n",
    "                         left_on = [token],\n",
    "                         right_on = [token], \n",
    "                         indicator = True)\n",
    "\n",
    "    # extract missing rows from df1\n",
    "    \n",
    "    df1_missing = df_merged[df_merged[\"_merge\"] == \"left_only\"]\n",
    "    df1_mis_token = list(df1_missing[token])\n",
    "    \n",
    "    # extract missing rows from df2\n",
    "    \n",
    "    df2_missing = df_merged[df_merged[\"_merge\"] == \"right_only\"]\n",
    "    df2_mis_token = list(df2_missing[token])\n",
    "    \n",
    "    # removing missing rows from both df1 and df2\n",
    "    \n",
    "    df1_clean = df1[~df1[token].isin(df1_mis_token)].sort_values(by = token)\n",
    "    df2_clean = df2[~df2[token].isin(df2_mis_token)].sort_values(by = token)\n",
    "    \n",
    "    df1_clean.reset_index(drop = True, inplace = True)\n",
    "    df2_clean.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # comparing datasets\n",
    "    \n",
    "    changes = df1_clean.compare(df2_clean)\n",
    "    \n",
    "    # extracting tokens for rows with differences\n",
    "    \n",
    "    changes[token] = [df1_clean[token].iloc[i] for i in changes.index]\n",
    "    changes.set_index(token, inplace = True)\n",
    "    \n",
    "    return df1_mis_token, df2_mis_token, changes\n",
    "\n",
    "# function to print different results based on whether there are changes\n",
    "\n",
    "def de_dupe_check(df1, df2, namecol, token):\n",
    "\n",
    "    mis1, mis2, change = de_dupe_clean(df1, df2, namecol, token)\n",
    "\n",
    "    # printing missing rows\n",
    "    \n",
    "    if len(mis1) > 0:\n",
    "        print (f\"The following {len(mis1)} tokens are missing from {name2}'s dataset: {mis1}\")\n",
    "    if len(mis2) > 0:\n",
    "        print (f\"The following {len(mis2)} tokens are missing from {name1}'s dataset: {mis2}\")\n",
    "    if len(mis1) == 0 and len(mis2) == 0:\n",
    "        print (\"number of rows are identical\")\n",
    "\n",
    "    # printing rows with differences\n",
    "        \n",
    "    print (\"\\n----------\\n\")\n",
    "    if len(change) == 0 and len(mis1) == 0 and len(mis2) == 0:\n",
    "        print (\"datasets are identical\")\n",
    "    elif len(change) == 0:\n",
    "        print (\"other than missing rows, datasets are identical\")\n",
    "    else:\n",
    "        results = pd.DataFrame(data = change)\n",
    "        results.to_excel(\"output/output.xlsx\")\n",
    "        \n",
    "de_dupe_check(data1, data2, namecol = namecol, token = token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-rwanda",
   "metadata": {},
   "source": [
    "# Check the output folder for the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-control",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
